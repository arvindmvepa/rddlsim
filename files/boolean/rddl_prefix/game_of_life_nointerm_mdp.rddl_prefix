domain game_of_life_mdp {
  requirements = {
    reward-deterministic
  };
  types {
    y_pos : object;
    x_pos : object;
  };
  pvariables {
    set(x_pos, y_pos) : {action-fluent, bool, default = false};
    NOISE-PROB(x_pos, y_pos) : {non-fluent, real, default = 0.1};
    alive(x_pos, y_pos) : {state-fluent, bool, default = false};
    NEIGHBOR(x_pos, y_pos, x_pos, y_pos) : {non-fluent, bool, default = false};
  };
  cpfs {
    (alive' ?x ?y) = (if (| (^ (alive ?x ?y) (>= (sum ( (?x2 : x_pos) (?y2 : y_pos) ) (^ (NEIGHBOR ?x ?y ?x2 ?y2) (alive ?x2 ?y2) )) 2) (<= (sum ( (?x2 : x_pos) (?y2 : y_pos) ) (^ (NEIGHBOR ?x ?y ?x2 ?y2) (alive ?x2 ?y2) )) 3) ) (^ (~ (alive ?x ?y)) (== (sum ( (?x2 : x_pos) (?y2 : y_pos) ) (^ (NEIGHBOR ?x ?y ?x2 ?y2) (alive ?x2 ?y2) )) 3) ) (set ?x ?y) ) then (Bernoulli (- 1.0 (NOISE-PROB ?x ?y))) else (Bernoulli (NOISE-PROB ?x ?y)));
  };
  reward = (sum ( (?x : x_pos) (?y : y_pos) ) (- (alive ?x ?y) (set ?x ?y)));
  state-action-constraints {
    (forall ( (?x : x_pos) (?y : y_pos) ) (^ (>= (NOISE-PROB ?x ?y) 0.0) (<= (NOISE-PROB ?x ?y) 1.0) ));
  };
}

non-fluents game2 {
  domain = game_of_life_mdp;
  objects {
    y_pos : {y1, y2};
    x_pos : {x1, x2};
  };
  non-fluents {
    NEIGHBOR(x1, y1, x1, y2);
    NEIGHBOR(x1, y1, x2, y1);
    NEIGHBOR(x1, y1, x2, y2);
    NEIGHBOR(x1, y2, x1, y1);
    NEIGHBOR(x1, y2, x2, y1);
    NEIGHBOR(x1, y2, x2, y2);
    NEIGHBOR(x2, y1, x1, y1);
    NEIGHBOR(x2, y1, x1, y2);
    NEIGHBOR(x2, y1, x2, y2);
    NEIGHBOR(x2, y2, x1, y1);
    NEIGHBOR(x2, y2, x1, y2);
    NEIGHBOR(x2, y2, x2, y1);
  };
}

non-fluents game3 {
  domain = game_of_life_mdp;
  objects {
    y_pos : {y1, y2, y3};
    x_pos : {x1, x2, x3};
  };
  non-fluents {
    NEIGHBOR(x1, y1, x1, y2);
    NEIGHBOR(x1, y1, x2, y1);
    NEIGHBOR(x1, y1, x2, y2);
    NEIGHBOR(x1, y2, x1, y1);
    NEIGHBOR(x1, y2, x2, y1);
    NEIGHBOR(x1, y2, x2, y2);
    NEIGHBOR(x1, y2, x2, y3);
    NEIGHBOR(x1, y2, x1, y3);
    NEIGHBOR(x1, y3, x1, y2);
    NEIGHBOR(x1, y3, x2, y2);
    NEIGHBOR(x1, y3, x2, y3);
    NEIGHBOR(x2, y1, x1, y1);
    NEIGHBOR(x2, y1, x1, y2);
    NEIGHBOR(x2, y1, x2, y2);
    NEIGHBOR(x2, y1, x3, y2);
    NEIGHBOR(x2, y1, x3, y1);
    NEIGHBOR(x2, y2, x1, y1);
    NEIGHBOR(x2, y2, x1, y2);
    NEIGHBOR(x2, y2, x1, y3);
    NEIGHBOR(x2, y2, x2, y1);
    NEIGHBOR(x2, y2, x2, y3);
    NEIGHBOR(x2, y2, x3, y1);
    NEIGHBOR(x2, y2, x3, y2);
    NEIGHBOR(x2, y2, x3, y3);
    NEIGHBOR(x2, y3, x1, y3);
    NEIGHBOR(x2, y3, x1, y2);
    NEIGHBOR(x2, y3, x2, y2);
    NEIGHBOR(x2, y3, x3, y2);
    NEIGHBOR(x2, y3, x3, y3);
    NEIGHBOR(x3, y1, x2, y1);
    NEIGHBOR(x3, y1, x2, y2);
    NEIGHBOR(x3, y1, x3, y2);
    NEIGHBOR(x3, y2, x3, y1);
    NEIGHBOR(x3, y2, x2, y1);
    NEIGHBOR(x3, y2, x2, y2);
    NEIGHBOR(x3, y2, x2, y3);
    NEIGHBOR(x3, y2, x3, y3);
    NEIGHBOR(x3, y3, x2, y3);
    NEIGHBOR(x3, y3, x2, y2);
    NEIGHBOR(x3, y3, x3, y2);
  };
}

instance glm1 {
  domain = game_of_life_mdp;
  non-fluents = game2;
  init-state {
    alive(x1, y1);
    alive(x1, y2);
  };
  max-nondef-actions = 1;
  horizon = 20;
  discount = 1.0;
}

instance glm2 {
  domain = game_of_life_mdp;
  non-fluents = game3;
  init-state {
    alive(x1, y1);
    alive(x1, y3);
    alive(x2, y2);
    alive(x3, y1);
    alive(x3, y3);
  };
  max-nondef-actions = 1;
  horizon = 20;
  discount = 1.0;
}

